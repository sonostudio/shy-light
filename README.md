# shy-light

Camera → detection → OSC bridge for interactive 3D lighting in Unreal Engine.

Detects proximity, facial expression, and peekaboo gestures from a webcam or
depth camera, and sends OSC signals to Unreal Engine on state changes.

---

## Setup

```bash
# 1. Create a virtual environment and install dependencies
uv sync

# 2. Download required MediaPipe models (~20MB, run once)
uv run python download_models.py

# 3. (Optional) RealSense camera support
uv add pyrealsense2
```

---

## Run

```bash
uv run shy-light
# or specify a custom config:
uv run shy-light --config config.yaml
```

Press **Q** in the preview window, or **Ctrl+C** in the terminal, to quit.

---

## Configuration

Edit `config.yaml` to adjust camera type, OSC target, and detection thresholds.

**Switch from webcam to RealSense:**
```yaml
camera:
  type: realsense   # ← change this
```

**Point OSC at a different machine (e.g. Unreal on another PC):**
```yaml
osc:
  host: 192.168.1.42   # ← Unreal Engine machine IP
  port: 7000
```

---

## OSC Message Schema

### Proximity (sent on state change)

| State          | Address             | Type   | Value     |
|----------------|---------------------|--------|-----------|
| Person close   | `/person/proximity` | string | `"close"` |
| Person medium  | `/person/proximity` | string | `"medium"`|
| Person far     | `/person/proximity` | string | `"far"`   |
| No face        | `/person/proximity` | string | `"none"`  |

### Proximity value (sent every frame)

| Address                  | Type  | Value                                          |
|--------------------------|-------|------------------------------------------------|
| `/person/proximity/value`| float | `0.0` (far / no face) → `1.0` (closest)       |

Use this for smooth continuous control e.g. driving light angle or intensity.
Recommended to lerp/smooth this value on the Unreal side to avoid jitter.

### Expression (sent on state change, suppressed during peekaboo)

| State   | Address              | Type   | Value      |
|---------|----------------------|--------|------------|
| Smile   | `/person/expression` | string | `"smile"`  |
| Angry   | `/person/expression` | string | `"angry"`  |
| Sad     | `/person/expression` | string | `"sad"`    |
| Neutral | `/person/expression` | string | `"neutral"`|

### Gesture (sent on state change)

| State    | Address           | Type   | Value       |
|----------|-------------------|--------|-------------|
| Peekaboo | `/person/gesture` | string | `"peekaboo"`|
| None     | `/person/gesture` | string | `"none"`    |

> **Note:** Expression is automatically set to `"none"` while peekaboo is active,
> since the face is covered and any reading would be noise.
> Proximity and proximity/value continue to be sent during peekaboo —
> handle any collision between the two on the Unreal side as needed.

To use **integer codes** instead of strings (if Unreal expects that),
set `USE_STRING_VALUES = False` in `osc/mapping.py`.

---

## Project Structure

```
shy-light/
├── camera/
│   ├── base.py             # Abstract CameraSource
│   ├── webcam.py           # OpenCV webcam
│   ├── realsense.py        # Intel RealSense
│   └── factory.py          # create_camera(config)
├── detectors/
│   ├── detector_base.py    # Abstract Detector
│   ├── proximity.py        # Face bbox → FAR/MEDIUM/CLOSE + float 0.0–1.0
│   ├── expression.py       # DeepFace → smile/angry/sad/neutral
│   └── peekaboo.py         # Face absence → peekaboo
├── state/
│   ├── schema.py           # Enums + DetectionResult
│   └── manager.py          # Debounce + change detection
├── osc/
│   ├── mapping.py          # OSC address + value map
│   └── sender.py           # python-osc UDP sender
├── models/                 # MediaPipe model files (generated by download_models.py)
├── main.py                 # Orchestrator / main loop
├── download_models.py      # One-time model downloader
├── debug_peekaboo.py       # Visual debugger for peekaboo detection
├── config.yaml             # All configuration
└── pyproject.toml
```